<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,viewport-fit=cover"><meta name=robots content="index, follow"><title>Code | AetherAI</title><meta name=description content><link rel=canonical href=https://frikallo.github.io/deliverables/code/><link crossorigin=anonymous href=/assets/css/stylesheet.min.538a5eddf95a593a32b416b321b420df71201416cb0038c0beea7528d0de0113.css integrity="sha256-U4pe3flaWToytBazIbQg33EgFBbLADjAvup1KNDeARM=" rel="preload stylesheet" as=style><link rel=preload href=/images/libre.svg as=image><link rel=preload href=/fonts/eleuther.woff2 as=font type=font/woff2 crossorigin><link rel=icon href=https://frikallo.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://frikallo.github.io/favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://frikallo.github.io/favicon/favicon-32x32.png><link rel=apple-touch-icon href=https://frikallo.github.io/favicon/apple-touch-icon.png><link rel=mask-icon href=https://frikallo.github.io/safari-pinned-tab.svg><link rel=manifest href=/manifest.webmanifest><meta name=apple-mobile-web-app-capable content="yes"><meta name=theme-color content="#000"><meta name=application-name content><meta name=msapplication-TileColor content="#000"><meta name=color-scheme content="light dark"><meta name=generator content="Hugo 0.95.0"><link rel=alternate type=application/rss+xml href=https://frikallo.github.io/deliverables/code/index.xml><script async src="https://www.googletagmanager.com/gtag/js?id=G-4SDKJXT0HF"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-4SDKJXT0HF",{anonymize_ip:!1})}</script><meta property="og:title" content="Code"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://frikallo.github.io/deliverables/code/"><meta property="og:image" content="https://eleuther.ai/images/promo.png"><meta property="og:site_name" content="AetherAI"><meta name=twitter:card content="summary"><meta name=twitter:image content="https://eleuther.ai/images/promo.png"><meta name=twitter:title content="Code"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@id":"https://frikallo.github.io/deliverables/code/","@type":"WebPage","name":"Code","publisher":{"@id":"https://frikallo.github.io/#org","@type":"Organization","name":"AetherAI","url":"https://frikallo.github.io/"}}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><div class=nav-container><a class=logo href=https://frikallo.github.io/ accesskey=h title="AetherAI (Alt + H)"><img src=/images/libre.svg alt=logo aria-label=logo width=48 height=48><span class=logotype>AetherAI</span></a><nav class=nav><ul id=menu><li><a href=https://frikallo.github.io/ title=Home><span>Home</span></a></li><li><a href=https://frikallo.github.io/about/ title=About><span>About</span></a></li><li><a href=https://frikallo.github.io/faq/ title=FAQ><span>FAQ</span></a></li><li><a href=https://frikallo.github.io/blog/ title=Blog><span>Blog</span></a></li><li><a href=https://frikallo.github.io/publications/ title=Publications><span>Publications</span></a></li></ul><button id=theme-toggle accesskey=t title="Theme Toggle (Alt + T)"><img src=/images/halfCircle.svg alt="dark mode switch button"></button></nav></div></header><main class=main><header class=page-header><h1>Code</h1></header><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="https://frikallo.github.io/projects/alphafold2/alphafold2_hu1f9e05c17c1f656ad4a30aef719965ae_49977_360x0_resize_q75_box.jpg 360w ,https://frikallo.github.io/projects/alphafold2/alphafold2_hu1f9e05c17c1f656ad4a30aef719965ae_49977_480x0_resize_q75_box.jpg 480w ,https://frikallo.github.io/projects/alphafold2/alphafold2.jpg 496w" sizes="(min-width: 768px) 720px, 100vw" src=https://frikallo.github.io/projects/alphafold2/alphafold2.jpg alt></figure><header class=entry-header><h2>AlphaFold2 Replication</h2></header><section class=entry-content><p>AlphaFold2 is a deep learning algorithm that leverages techniques originating in natural language processing to do protein structure prediction. It was announced by DeepMind in 2020 at the CASP 14 competition where it stunned the competition with its performance. The creators have given several talks and presentations on the algorithm (see, e.g., here), the model and codebase has been very recently (Jul 15, 2021) open sourced (under Apache License, Version 2....</p></section><a class=entry-link aria-label="post link to AlphaFold2 Replication" href=https://frikallo.github.io/projects/alphafold2/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="https://frikallo.github.io/projects/carp/carp_hu3c5d2448daeffff03caf3f83f0dde3a1_663638_360x0_resize_box_3.png 360w ,https://frikallo.github.io/projects/carp/carp_hu3c5d2448daeffff03caf3f83f0dde3a1_663638_480x0_resize_box_3.png 480w ,https://frikallo.github.io/projects/carp/carp.png 496w" sizes="(min-width: 768px) 720px, 100vw" src=https://frikallo.github.io/projects/carp/carp.png alt></figure><header class=entry-header><h2>CARP</h2></header><section class=entry-content><p></p></section><a class=entry-link aria-label="post link to CARP" href=https://frikallo.github.io/projects/carp/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="https://frikallo.github.io/projects/clasp/clasp_huf70fe6829901c42c21c6b13cd4d91958_812507_360x0_resize_box_3.png 360w ,https://frikallo.github.io/projects/clasp/clasp_huf70fe6829901c42c21c6b13cd4d91958_812507_480x0_resize_box_3.png 480w ,https://frikallo.github.io/projects/clasp/clasp.png 512w" sizes="(min-width: 768px) 720px, 100vw" src=https://frikallo.github.io/projects/clasp/clasp.png alt></figure><header class=entry-header><h2>CLASP</h2></header><section class=entry-content><p>Recently multimodal contrastive models have had an explosion in power and popularity, e.g., ConVIRT, CLIP, and ALIGN. In this project we apply a similar setup but use amino acid sequences and their language description as our training data from the Universal Protein Resource (UniProt), an annotated protein database. The goal is to create a model that can be used like other CLIP-like models but for amino acid sequences and text....</p></section><a class=entry-link aria-label="post link to CLASP" href=https://frikallo.github.io/projects/clasp/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="https://frikallo.github.io/projects/lm-eval/lm-eval_hu5d0e65d60bfda2b0c82fd13129d1122a_444375_360x0_resize_box_3.png 360w ,https://frikallo.github.io/projects/lm-eval/lm-eval_hu5d0e65d60bfda2b0c82fd13129d1122a_444375_480x0_resize_box_3.png 480w ,https://frikallo.github.io/projects/lm-eval/lm-eval.png 512w" sizes="(min-width: 768px) 720px, 100vw" src=https://frikallo.github.io/projects/lm-eval/lm-eval.png alt></figure><header class=entry-header><h2>Eval Harness</h2></header><section class=entry-content><p>Github Repo: https://github.com/EleutherAI/lm-evaluation-harness</p></section><a class=entry-link aria-label="post link to Eval Harness" href=https://frikallo.github.io/projects/lm-eval/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="https://frikallo.github.io/projects/gpt-neo/gpt-neo_hu55b8d0ce196310b116530ae663df3363_433213_360x0_resize_box_3.png 360w ,https://frikallo.github.io/projects/gpt-neo/gpt-neo_hu55b8d0ce196310b116530ae663df3363_433213_480x0_resize_box_3.png 480w ,https://frikallo.github.io/projects/gpt-neo/gpt-neo.png 512w" sizes="(min-width: 768px) 720px, 100vw" src=https://frikallo.github.io/projects/gpt-neo/gpt-neo.png alt></figure><header class=entry-header><h2>GPT-Neo</h2></header><section class=entry-content><p>GPT-Neo is an implementation of model & data-parallel autoregressive language models, utilizing Mesh Tensorflow for distributed computation on TPUs.
GPT-Neo is considered deprecated and is no longer maintained. We suggest that those looking for a TPU-centric codebase use Mesh Transformer JAX instead.</p></section><a class=entry-link aria-label="post link to GPT-Neo" href=https://frikallo.github.io/projects/gpt-neo/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="https://frikallo.github.io/projects/gpt-neox/gpt-neox_hud8b3502bcaa4111a79e17298cec1cea5_516865_360x0_resize_box_3.png 360w ,https://frikallo.github.io/projects/gpt-neox/gpt-neox_hud8b3502bcaa4111a79e17298cec1cea5_516865_480x0_resize_box_3.png 480w ,https://frikallo.github.io/projects/gpt-neox/gpt-neox.png 512w" sizes="(min-width: 768px) 720px, 100vw" src=https://frikallo.github.io/projects/gpt-neox/gpt-neox.png alt></figure><header class=entry-header><h2>GPT-NeoX</h2></header><section class=entry-content><p>GPT-NeoX is an implementation of 3D-parallel GPT-3-like autoregressive language models for distributed GPUs, based upon Megatron-LM and DeepSpeed.</p></section><a class=entry-link aria-label="post link to GPT-NeoX" href=https://frikallo.github.io/projects/gpt-neox/></a></article><article class="post-entry tag-entry"><figure class=entry-cover><img loading=lazy srcset="https://frikallo.github.io/projects/mesh-transformer-jax/mesh-transformer-jax_hu8f3cd72a3bcfcbb5bba9b838240e13a1_487710_360x0_resize_box_3.png 360w ,https://frikallo.github.io/projects/mesh-transformer-jax/mesh-transformer-jax_hu8f3cd72a3bcfcbb5bba9b838240e13a1_487710_480x0_resize_box_3.png 480w ,https://frikallo.github.io/projects/mesh-transformer-jax/mesh-transformer-jax.png 512w" sizes="(min-width: 768px) 720px, 100vw" src=https://frikallo.github.io/projects/mesh-transformer-jax/mesh-transformer-jax.png alt></figure><header class=entry-header><h2>Mesh Transformer JAX</h2></header><section class=entry-content><p>Mesh Transformer JAX is an implementation of model & data-parallel autoregressive language models, utilizing Haiku and the xmap/pjit operators in JAX to distribute computation on TPUs.
As the designated successor to GPT-Neo, Mesh Transformer JAX was used to train GPT-J-6B, a six billion parameter language model. For more information on Mesh Transformer JAX and GPT-J-6B, see the blog post by Aran Komatsuzaki.</p></section><a class=entry-link aria-label="post link to Mesh Transformer JAX" href=https://frikallo.github.io/projects/mesh-transformer-jax/></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://frikallo.github.io/>AetherAI</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById("menu");menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>